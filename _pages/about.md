---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am currently at the Artificial Intelligence Research Institute of Soochow University, advised by [Assoc. Prof. Juntao Li(æä¿Šæ¶›)](https://lijuntaopku.github.io/) and [Prof. Min Zhang(å¼ æ°‘)](https://scholar.google.com/citations?hl=zh-CN&user=CncXH-YAAAAJ).

Before this, I received my Bachelorâ€™s degree (2018-2022, computer science) from Soochow University.

I am currently working as a research intern at [Shanghai AI Laboratory](https://www.shlab.org.cn/) General Technology Research under the mentorship of [Xiaoye Qu(ç¿æ™“æ™”)](https://scholar.google.com/citations?user=rT3hqdcAAAAJ&hl=zh-CN) and [Yu Cheng(æˆå®‡)](https://scholar.google.com/citations?user=ORPxbV4AAAAJ&hl=zh-CN).




ğŸ¤” My research interests are primarily focused on exploring various challenges related to the dynamic of **"time"** in machine learning. Currently, my main focus is on Large Language Models (LLMs), covering the following topics:
- **Adaptation and Generalization:** Focusing on the reasons behind model degradation in time and exploring the strategies to improve temporal generalization and update the knowledge without catastrophic forgetting of old knowledge.
- **Trustworthiness and Reliability:** Investigation into the behavior of LLMs when encountering knowledge
conflicts and exploring methods to mitigate knowledge conflicts of old knowledge as we update LLMs with new knowledge.
- **Complex reasoning:** Research on equipping LLMs with human-level temporal reasoning and commonsense. This involves
basic temporal concepts understanding and intricate temporal interpretations and computations.

ğŸ“– *Can the progress of civilization, and the advancement of technology truly transcend time? Or are we just endlessly pursuing the elusive dust in the hourglass?*

ğŸ¤ **I'm looking for a PhD position in 2025 Fall. Don't hesitate to email me if there is a potential opportunity!**

# ğŸ”¥ News
- *2024.7*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by COLM 2024!
- *2024.6*: &nbsp;ğŸ‰ğŸ‰ Invited talk on [temporal reasoning](https://www.bilibili.com/video/BV1SJ4m1u7Cg/?spm_id_from=333.337.search-card.all.click&vd_source=cb56bffcd72c8f46eaea59a666b85547) at NICE!
- *2024.5*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by ACL 2024 <font color='red'> oral </font>!
- *2023.10*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by EMNLP 2023!
- *2022.10*: &nbsp;ğŸ‰ğŸ‰ One paper is accepted by EMNLP 2022!

# ğŸ“ Publications 

- ``COLM 2024`` [Timo: Towards Better Temporal Reasoning for Language Models](https://arxiv.org/pdf/2406.14192), **Zhaochen Su**, Jun Zhang, Tong Zhu, Xiaoye Qu, Juntao Li, Min Zhang, Yu Cheng.

- ``ACL 2024 oral`` [Living in the Moment: Can Large Language Models Grasp Co-Temporal Reasoning?](https://arxiv.org/pdf/2406.09072), **Zhaochen Su**, Juntao Li, Jun Zhang, Tong Zhu, Xiaoye Qu, Pan Zhou, Yan Bowen, Yu Cheng, Min zhang

- ``EMNLP 2023`` [Efficient Continue Training of Temporal Language Model with Structural Information](https://aclanthology.org/2023.findings-emnlp.418.pdf), **Zhaochen Su**, Juntao Li, Zikang Zhang, Zihan Zhou, Min Zhang

- ``EMNLP 2022`` [Improving Temporal Generalization of Pre-trained Language Models with Lexical Semantic Change](https://aclanthology.org/2022.emnlp-main.428.pdf), **Zhaochen Su**, Zecheng Tang, Xinyan Guan, Lijun Wu, Min Zhang, Juntao Li

- ``Submission to Neurips-24`` ConflictBank: A Benchmark for Evaluating Knowledge Conflicts in Large Language Models, **Zhaochen Su**, Jun Zhang, Xiaoye Qu, Tong Zhu, Yanshu Li, Jiashuo Sun, Juntao Li, Min Zhang, Yu Cheng.

- ``Submission to AI-Journal`` Language Model Adaptation as Lexical Semantic Change Modeling, **Zhaochen Su**, Zikang Zhang, Juntao Li, Lijun Wu, Zecheng Tang, Min Zhang.

  
# ğŸ– Honors and Awards
- Soochow University Graduate Outstanding Scholarship (Rank 1st)
- The Samsung Scholarship
- China Software Design Competition -- First Prize (National Level, Team Leader)
- Chinese Collegiate Computing Competition -- Second Prize (National Level, Team Leader)

# ğŸ“– Educations
- *2022.09 - current*, Second-year Master, Artificial Intelligence Research Institute, Soochow University, Suzhou.
- *2018.09 - 2022.06*, Bachelor, Institute of Computer Science and Technology, Soochow University, Suzhou.
- *2021.07 - 2022.07*, Dual Degree, Brain Science, Soochow University, Suzhou.

# ğŸ’ Volunteer
- Conference Reviewer: ARR, ACL-24, EMNLP-24, MM-24
- *2023.09 - current*, Soochow University Graduate Student Union - President
- *2020.05 - 2021.05*, Studentsâ€™ International Communication Association (SICA) - President



# ğŸ’» Internships
- *2023.10 - current*, [Shanghai AI Laboratory](https://www.shlab.org.cn/), China.
- *2021.06 - 2021.09*, [World Heritage Institute of Training and Research for the Asia and the Pacific Region under the auspices of UNESCO](http://www.whitr-ap.org/), China.


# ğŸ¨ Miscellaneous
Without any special circumstances, I exercise for **1 hour** every day. Here are some of my favorite sports and personal achievements: ğŸ‹ï¸ fitness (Progressive Overload (PR): bench press 98.5 kg, squat 140 kg, deadlift 135 kg), ğŸ“ table tennis (amateur intermediate), ğŸ¾ tennis (skill level: 2.5), ğŸƒ running (5 km/h, 10 km pace), ğŸš´ cycling (25.5 km/h, 50 km pace).

If you share similar hobbies, please feel free to reach out and connect!
